{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bba857d-3bbd-4527-a89d-a29c2f220b8c",
   "metadata": {},
   "source": [
    "# Concrete Compressive Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35df53-f25e-4a04-a7b5-03ea9ca7a9ce",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb098a90-e1f2-4a93-955b-9a083178d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1cba8-7307-4f29-a464-fa21a0755545",
   "metadata": {},
   "source": [
    "### Importing Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a03d5b94-6a19-41ea-ae10-1aa0f8a0c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data=pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba5a75da-21ef-40c4-bdf0-fdac1355a55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c44fb2fc-9840-435e-a1a1-733c836e96c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9caab538-7079-40ee-a4af-a08b2de3bd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed518c91-085a-423d-8d45-dff6c3ca65f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef1432e0-45b9-4e9a-a170-01508f04a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Cement              1030 non-null   float64\n",
      " 1   Blast Furnace Slag  1030 non-null   float64\n",
      " 2   Fly Ash             1030 non-null   float64\n",
      " 3   Water               1030 non-null   float64\n",
      " 4   Superplasticizer    1030 non-null   float64\n",
      " 5   Coarse Aggregate    1030 non-null   float64\n",
      " 6   Fine Aggregate      1030 non-null   float64\n",
      " 7   Age                 1030 non-null   int64  \n",
      " 8   Strength            1030 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.6 KB\n"
     ]
    }
   ],
   "source": [
    "concrete_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32dd9f4a-2cb2-4bf4-8da3-32acb1ad86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols= concrete_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154fbb7-fa9d-449c-855b-283e073e1a34",
   "metadata": {},
   "source": [
    "### Defining predictor and Target Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead73598-e5c3-47b6-8a50-a92309b7068d",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f31ab61-a603-4b12-8f82-04dca6dc1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorsX=concrete_data[cols[cols!='Strength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f3b62bb-c56c-4a7b-8f42-339c5b7cf8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictorsX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f5e6f57-9cbb-44b4-a772-aed0f4c24b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetY=concrete_data['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b6dc0ec6-5a2d-4429-a00c-9bce697c6f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2176c4ca-a84c-4ba2-a00e-6236a7cb39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols=predictorsX.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff629c8c-18df-40f6-8ba0-0ff27d784e26",
   "metadata": {},
   "source": [
    "### Defining the Model with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac09b5cd-ccfd-4ce0-89e5-dd055e2d9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model1():\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(pred_cols,)))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bda27b-cfcf-4a88-be21-79ec00d423fd",
   "metadata": {},
   "source": [
    "### Defining function to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a56856c-4459-498b-925d-6aaab986f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X,Y, regression_model,epochs):\n",
    "    \n",
    "    mse_list=[]\n",
    "    \n",
    "    for epoc in range(epochs):\n",
    "    \n",
    "        model=regression_model\n",
    "        \n",
    "        xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "        \n",
    "        model.fit(xtrain,ytrain,epochs=50,verbose=0)\n",
    "        \n",
    "        y_predict=model.predict(xtest)\n",
    "        \n",
    "        mse=mean_squared_error(ytest,y_predict)\n",
    "        mse_list.append(mse)\n",
    "        \n",
    "        print(f\"Run {epoc+1}, MSE: {mse}\")\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the MSE values\n",
    "    mean_mse = np.mean(mse_list)\n",
    "    std_mse = np.std(mse_list)\n",
    "    \n",
    "    print(f\"Mean MSE: {mean_mse}\")\n",
    "    print(f\"Standard Deviation of MSE: {std_mse}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "432151ce-4af7-43d0-86ea-13b239f6fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 1, MSE: 230.71931653038166\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 2, MSE: 119.80531137125028\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Run 3, MSE: 93.28201999469883\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 4, MSE: 78.0637698310586\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 5, MSE: 63.470151061498555\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 6, MSE: 58.14891208560888\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 7, MSE: 51.559095975461034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 8, MSE: 51.29153569282839\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 9, MSE: 50.968650576273866\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 10, MSE: 49.10793361575202\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 11, MSE: 49.235633341709594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 12, MSE: 48.573175029803615\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 13, MSE: 58.87900500554641\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 14, MSE: 60.18527542489415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 15, MSE: 49.220222924656134\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 16, MSE: 48.03047435651991\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 17, MSE: 56.34327127872705\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 18, MSE: 48.948477257536\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 19, MSE: 49.55287278582678\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 20, MSE: 49.48067955051015\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 21, MSE: 50.996469543235335\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 22, MSE: 47.99871504342737\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 23, MSE: 48.36568680681594\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Run 24, MSE: 48.16340833489796\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 25, MSE: 49.12478450915723\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 26, MSE: 54.82059242699549\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 27, MSE: 48.95279083360248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 28, MSE: 49.937136463370294\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 29, MSE: 47.93814434816994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 30, MSE: 48.26359721332312\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 31, MSE: 48.58893051201239\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 32, MSE: 48.59036083007605\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 33, MSE: 55.54396538377089\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 34, MSE: 47.865105136185036\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 35, MSE: 47.783610398802175\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 36, MSE: 53.171802880426945\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 37, MSE: 49.760345539444714\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 38, MSE: 48.45596868552118\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 39, MSE: 47.99833525077082\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 40, MSE: 48.03154923624503\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 41, MSE: 51.40087063323947\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step \n",
      "Run 42, MSE: 52.88826763936189\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 43, MSE: 50.108112306441\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 44, MSE: 51.54996718705457\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 45, MSE: 48.677964254507984\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 46, MSE: 49.155375791449686\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 47, MSE: 52.68886305355736\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 48, MSE: 48.766761812204955\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 49, MSE: 48.02824034016863\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 50, MSE: 48.932363345559175\n",
      "Mean MSE: 57.14827738860676\n",
      "Standard Deviation of MSE: 27.66238793084756\n"
     ]
    }
   ],
   "source": [
    "model_training(predictorsX,targetY,regression_model=regression_model1(),epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c4885-f954-430e-ae60-cbe147973350",
   "metadata": {},
   "source": [
    "### Normalising the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c2f10-599f-4d88-b9a7-f6a685f778bb",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecf8168c-47b4-472c-8baf-ef8eca1dd938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.477915</td>\n",
       "      <td>-0.856888</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>-0.916764</td>\n",
       "      <td>-0.620448</td>\n",
       "      <td>0.863154</td>\n",
       "      <td>-1.217670</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.477915</td>\n",
       "      <td>-0.856888</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>-0.916764</td>\n",
       "      <td>-0.620448</td>\n",
       "      <td>1.056164</td>\n",
       "      <td>-1.217670</td>\n",
       "      <td>-0.279733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491425</td>\n",
       "      <td>0.795526</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>2.175461</td>\n",
       "      <td>-1.039143</td>\n",
       "      <td>-0.526517</td>\n",
       "      <td>-2.240917</td>\n",
       "      <td>3.553066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491425</td>\n",
       "      <td>0.795526</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>2.175461</td>\n",
       "      <td>-1.039143</td>\n",
       "      <td>-0.526517</td>\n",
       "      <td>-2.240917</td>\n",
       "      <td>5.057677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790459</td>\n",
       "      <td>0.678408</td>\n",
       "      <td>-0.847144</td>\n",
       "      <td>0.488793</td>\n",
       "      <td>-1.039143</td>\n",
       "      <td>0.070527</td>\n",
       "      <td>0.647884</td>\n",
       "      <td>4.978487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.477915           -0.856888 -0.847144 -0.916764         -0.620448   \n",
       "1  2.477915           -0.856888 -0.847144 -0.916764         -0.620448   \n",
       "2  0.491425            0.795526 -0.847144  2.175461         -1.039143   \n",
       "3  0.491425            0.795526 -0.847144  2.175461         -1.039143   \n",
       "4 -0.790459            0.678408 -0.847144  0.488793         -1.039143   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.863154       -1.217670 -0.279733  \n",
       "1          1.056164       -1.217670 -0.279733  \n",
       "2         -0.526517       -2.240917  3.553066  \n",
       "3         -0.526517       -2.240917  5.057677  \n",
       "4          0.070527        0.647884  4.978487  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "\n",
    "predictors=pd.DataFrame(scaler.fit_transform(predictorsX),columns=predictorsX.columns)\n",
    "target = pd.DataFrame(scaler.fit_transform(targetY.values.reshape(-1, 1)), columns=['target'])\n",
    "\n",
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2332d2aa-cb38-48e6-8f9a-ed6eda97cc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.645408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.561421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.507979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0  2.645408\n",
       "1  1.561421\n",
       "2  0.266627\n",
       "3  0.313340\n",
       "4  0.507979"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7eae17d-e228-4982-a0bb-22bc7358f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 1, MSE: 0.23058902216231733\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Run 2, MSE: 0.16388995623054925\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 3, MSE: 0.152897291004724\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 4, MSE: 0.15018084099400736\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 5, MSE: 0.14665957969817725\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 6, MSE: 0.14493377408814292\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 7, MSE: 0.14374800171005864\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 8, MSE: 0.14017069860083034\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 9, MSE: 0.13526830161477543\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 10, MSE: 0.13395114759394408\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 11, MSE: 0.12937271862000627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 12, MSE: 0.12510341601588593\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 13, MSE: 0.12445463526106948\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 14, MSE: 0.12247520167409248\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 15, MSE: 0.12320557310255943\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 16, MSE: 0.12276308480359506\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 17, MSE: 0.12331304826990899\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 18, MSE: 0.12161081977669456\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 19, MSE: 0.12164862201970435\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 20, MSE: 0.12226781606214163\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 21, MSE: 0.12274472623269532\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 22, MSE: 0.12235453053831714\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 23, MSE: 0.12095511678812272\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 24, MSE: 0.12308437604920949\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Run 25, MSE: 0.12287199335006908\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 26, MSE: 0.12282641402731875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 27, MSE: 0.12260621056967866\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 28, MSE: 0.12280648235451144\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 29, MSE: 0.12180745551079246\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 30, MSE: 0.12315015268944965\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 31, MSE: 0.12206541609402442\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 32, MSE: 0.12140054342525558\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 33, MSE: 0.1210722246278815\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 34, MSE: 0.1220929843358916\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 35, MSE: 0.12163934814568926\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 36, MSE: 0.12138769434274933\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 37, MSE: 0.12083427175387951\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 38, MSE: 0.1204647936776326\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 39, MSE: 0.12271351973052992\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 40, MSE: 0.12064667379947959\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 41, MSE: 0.12205980391558888\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 42, MSE: 0.12052613080912498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 43, MSE: 0.12254255461598655\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 44, MSE: 0.12196334167164165\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 45, MSE: 0.12205485066669083\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 46, MSE: 0.12241557790548831\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 47, MSE: 0.1217530724149426\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 48, MSE: 0.122978514938872\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 49, MSE: 0.12229412238809127\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 50, MSE: 0.12147891022484388\n",
      "Mean MSE: 0.12876190713795266\n",
      "Standard Deviation of MSE: 0.017525975377084838\n"
     ]
    }
   ],
   "source": [
    "model_training(predictors,target,regression_model=regression_model1(),epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8c24c4-fc20-47de-b91b-a2d884005017",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) of the model decreased dramatically from 57.15 in Part A to 0.128 in Part B, despite using the same number of epochs for training.\n",
    "\n",
    "Insights:\n",
    "Effect of Data Normalization: The key difference between Part A and Part B is the normalization of the data. Normalizing the predictors likely improved the model's ability to converge by ensuring that all features contributed proportionally to the learning process. This step helps prevent large-scale features from dominating smaller-scale ones, leading to a significant reduction in prediction error.\n",
    "\n",
    "Same Epochs, Better Results: The same number of epochs achieved better performance in Part B due to improved input data quality, emphasizing the importance of preprocessing in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86837146-d088-40a7-98fe-b97b0bb86766",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23516484-76a2-4523-91e2-de7fe12a4b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Run 1, MSE: 0.20876835680507777\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "Run 2, MSE: 0.16963520845966798\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Run 3, MSE: 0.1626825832057825\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 4, MSE: 0.15766278776029052\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "Run 5, MSE: 0.15002866183207866\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "Run 6, MSE: 0.1457243912065982\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "Run 7, MSE: 0.1457144962452833\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 8, MSE: 0.14183553237746294\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 9, MSE: 0.13947058703526505\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 10, MSE: 0.1394210246280596\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 11, MSE: 0.13801589449794174\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 12, MSE: 0.13642319126903693\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 13, MSE: 0.13665119754550534\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 14, MSE: 0.13503661870824313\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 15, MSE: 0.13609931648125007\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 16, MSE: 0.13708980059640588\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 17, MSE: 0.13581140008338385\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 18, MSE: 0.1365113831936887\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 19, MSE: 0.13677331390262046\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 20, MSE: 0.1351797101276413\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Run 21, MSE: 0.13754258543390285\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 22, MSE: 0.1356590362418332\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Run 23, MSE: 0.13752005596189526\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 24, MSE: 0.13623443833361054\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 25, MSE: 0.1371914163880269\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 26, MSE: 0.13716927428888515\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 27, MSE: 0.13748048509853084\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Run 28, MSE: 0.13569714857457751\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 29, MSE: 0.13780478222202627\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Run 30, MSE: 0.13656443238322746\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 31, MSE: 0.1357312442804894\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Run 32, MSE: 0.13672705739977506\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 33, MSE: 0.13654158291098517\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 34, MSE: 0.13778773531809094\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 35, MSE: 0.13781563032768734\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 36, MSE: 0.13847087981394363\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 37, MSE: 0.13918159217327775\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 38, MSE: 0.13780779571446095\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 39, MSE: 0.13683567825749193\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 40, MSE: 0.13625565258823252\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 41, MSE: 0.13656328900272668\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Run 42, MSE: 0.13601833835052518\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 43, MSE: 0.13617092889500818\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 44, MSE: 0.13620116585478367\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 45, MSE: 0.1364324532075767\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 46, MSE: 0.13539913987533478\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 47, MSE: 0.1360928277155628\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 48, MSE: 0.13623484872034206\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Run 49, MSE: 0.1341166063315332\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 50, MSE: 0.1351005246071033\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 51, MSE: 0.13566978836501956\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Run 52, MSE: 0.13575329180001722\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 53, MSE: 0.13475650668216393\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 54, MSE: 0.13482674187433558\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 55, MSE: 0.13577002450254994\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 56, MSE: 0.13433211876552978\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 57, MSE: 0.13630605332181617\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Run 58, MSE: 0.13499385256671648\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 59, MSE: 0.13644060838969913\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 60, MSE: 0.13575152547601751\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 61, MSE: 0.13547944960725805\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 62, MSE: 0.13725842761024046\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 63, MSE: 0.13594533181991575\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 64, MSE: 0.13524655346430456\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 65, MSE: 0.1367994722432096\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 66, MSE: 0.13382445291794887\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 67, MSE: 0.13570712396266946\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 68, MSE: 0.13544482196263752\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 69, MSE: 0.13602140320048114\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 70, MSE: 0.13427426058633027\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Run 71, MSE: 0.13458207964902352\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 72, MSE: 0.13603110596461102\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 73, MSE: 0.1355393398470337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 74, MSE: 0.13590534587087647\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 75, MSE: 0.13432936573428228\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Run 76, MSE: 0.13513998351774947\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 77, MSE: 0.1379206342307075\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 78, MSE: 0.1337738031153804\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 79, MSE: 0.13558151000357682\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 80, MSE: 0.1345948230072642\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 81, MSE: 0.1341830101236544\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 82, MSE: 0.1363605594062702\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 83, MSE: 0.13435059183269546\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 84, MSE: 0.13500087112386325\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 85, MSE: 0.13837145020140804\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 86, MSE: 0.13463197789430315\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 87, MSE: 0.13752988543210548\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Run 88, MSE: 0.13578969001232538\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 89, MSE: 0.1349908473572044\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 90, MSE: 0.1352423553435943\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 91, MSE: 0.135697951991188\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 92, MSE: 0.1361281293170651\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 93, MSE: 0.13566274804527662\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 94, MSE: 0.13671564883076154\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 95, MSE: 0.13689032821728309\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 96, MSE: 0.13424032569232178\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 97, MSE: 0.1368337910481625\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 98, MSE: 0.1336665812503446\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 99, MSE: 0.1347421840033787\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 100, MSE: 0.1331024400779602\n",
      "Mean MSE: 0.13799015249493266\n",
      "Standard Deviation of MSE: 0.008822991258179983\n"
     ]
    }
   ],
   "source": [
    "model_training(predictors,target,regression_model=regression_model1(),epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564856ae-aa9e-4f8e-8a85-72059026f59e",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) increased slightly from 0.128 in Part B to 0.138 in Part C, despite increasing the number of epochs during training.\n",
    "\n",
    "Insights:\n",
    "Diminishing Returns on Epochs: The slight increase in MSE indicates that simply increasing the number of epochs does not always lead to better performance. This could be due to the model reaching its optimal learning capacity within the initial epochs, and further training may introduce noise or overfitting.\n",
    "\n",
    "Plateau in Model Performance: The lack of significant improvement suggests that the model might have already converged in Part B. Additional epochs are not contributing meaningful learning and could instead be causing minor fluctuations in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c76cd2-7831-4d27-a4e0-55ee3274b6a8",
   "metadata": {},
   "source": [
    "### Defining model with 3 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06cc7ef-1236-4a08-96ea-9bf9d1be3750",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7504e83f-d1c8-42ad-adb6-5f66b8270cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model2():\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(pred_cols,)))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1fb2454-2319-438a-ba19-1132439c49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Run 1, MSE: 0.18462158980362564\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 2, MSE: 0.16048986508870816\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 3, MSE: 0.15759415604827692\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 4, MSE: 0.15404935223153002\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 5, MSE: 0.14958466949899288\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 6, MSE: 0.14645642582019525\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 7, MSE: 0.1442186207645002\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 8, MSE: 0.14259625392652212\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 9, MSE: 0.14143552357397376\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 10, MSE: 0.13830933424130964\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 11, MSE: 0.13927915567275645\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 12, MSE: 0.1373793233713859\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 13, MSE: 0.13512744530635512\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 14, MSE: 0.13417024007896394\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 15, MSE: 0.1340961168250047\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 16, MSE: 0.13404576121079065\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 17, MSE: 0.1354758977876382\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 18, MSE: 0.13915035034622816\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 19, MSE: 0.13272757668054472\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Run 20, MSE: 0.1338252253049053\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 21, MSE: 0.1323435857846232\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 22, MSE: 0.13349346220108846\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 23, MSE: 0.13309255611883283\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 24, MSE: 0.13492666541262574\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 25, MSE: 0.1339494034946922\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 26, MSE: 0.13195965923165492\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 27, MSE: 0.13744801736109646\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 28, MSE: 0.13571451859672337\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 29, MSE: 0.13360234682305033\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 30, MSE: 0.1351299974577928\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 31, MSE: 0.13497959292302975\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Run 32, MSE: 0.13554613620073058\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 33, MSE: 0.13472535647286124\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Run 34, MSE: 0.13548209138454215\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 35, MSE: 0.13418760869113242\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Run 36, MSE: 0.1345552385140031\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Run 37, MSE: 0.14070068765429605\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 38, MSE: 0.13552545212719516\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 39, MSE: 0.13366263092601752\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 40, MSE: 0.13365871767616191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Run 41, MSE: 0.13363137411736517\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 42, MSE: 0.1376942738834569\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 43, MSE: 0.13969701111103786\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 44, MSE: 0.13611313055325852\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 45, MSE: 0.1346277343017071\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 46, MSE: 0.13558180322775581\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 47, MSE: 0.13704414132090229\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 48, MSE: 0.13407960160744\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Run 49, MSE: 0.13583272181281875\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 50, MSE: 0.13570075047114727\n",
      "Mean MSE: 0.13858638302082496\n",
      "Standard Deviation of MSE: 0.008989389027081417\n"
     ]
    }
   ],
   "source": [
    "model_training(predictors,target,regression_model=regression_model2(),epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e35c3-ea9c-4e9a-bbb6-3d776d5cfa89",
   "metadata": {},
   "source": [
    "The mean squared error (MSE) increased from 0.128 in Part B to 0.138 in Part D when the number of hidden layers was increased.\n",
    "\n",
    "Insights:\n",
    "Impact of Additional Complexity: Increasing the number of hidden layers adds complexity to the model, potentially making it harder to generalize to unseen data. This could explain the slight increase in MSE, as the model may have started to overfit the training data or faced challenges in optimizing effectively.\n",
    "\n",
    "Saturation of Learning: The performance plateau suggests that the dataset and problem complexity may not require additional hidden layers. For relatively simple tasks or datasets, adding more layers can introduce redundancy and unnecessary computational overhead without improving results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb9ca5f-9350-4c3e-b97a-24d04b0136df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b482a5c4-cffa-4580-b4a3-758cd6cb3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Input(shape=(pred_cols,)))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6ef016e2-1cd4-4e52-9ab3-10f285790c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential_207, built=True>\n"
     ]
    }
   ],
   "source": [
    "model=regression_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e5f87056-188a-485b-a514-4d97c7a36ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Run 1, MSE: 0.10994450366759112\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 2, MSE: 0.09215148951827913\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 3, MSE: 0.10415949157450806\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 4, MSE: 0.1006872824279386\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 5, MSE: 0.09930534807903013\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 6, MSE: 0.09606451478991945\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 7, MSE: 0.09993776524167408\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 8, MSE: 0.09387736092936191\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 9, MSE: 0.10590069836506959\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step \n",
      "Run 10, MSE: 0.09409904332017477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 11, MSE: 0.09806748282744616\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 12, MSE: 0.09415499166925512\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 13, MSE: 0.09935062591805348\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 14, MSE: 0.0952976598056695\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 15, MSE: 0.09614935441114195\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 16, MSE: 0.09884559854299362\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 17, MSE: 0.09874447861504511\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n",
      "Run 18, MSE: 0.0977213881789312\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 19, MSE: 0.09787585657476057\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 20, MSE: 0.1015986889399763\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 21, MSE: 0.09813639952366092\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 22, MSE: 0.09850066599911737\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 23, MSE: 0.104011203789162\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 24, MSE: 0.10039067399069884\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 25, MSE: 0.1007214192721367\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 26, MSE: 0.10353041663545269\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 27, MSE: 0.10614432908775921\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 28, MSE: 0.10434449893396125\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 29, MSE: 0.103689364718614\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 30, MSE: 0.10797493129476049\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 31, MSE: 0.10517438654306015\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 32, MSE: 0.10761854483074816\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 33, MSE: 0.10553084455958324\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 34, MSE: 0.1056818821456076\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 35, MSE: 0.10578185217267946\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Run 36, MSE: 0.10381759279413998\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 37, MSE: 0.1037115525330024\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 38, MSE: 0.10473934259204089\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 39, MSE: 0.10625586503385047\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 40, MSE: 0.1020151056586049\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "Run 41, MSE: 0.10444326031822494\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 42, MSE: 0.10193261460398735\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 43, MSE: 0.10617959229506999\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 44, MSE: 0.10333609794208656\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 45, MSE: 0.10408972862388145\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 46, MSE: 0.09972445036038342\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "Run 47, MSE: 0.09976457805447432\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Run 48, MSE: 0.09812422854268477\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Run 49, MSE: 0.10060152323552297\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Run 50, MSE: 0.09951920822011101\n",
      "Mean MSE: 0.10138839555403775\n",
      "Standard Deviation of MSE: 0.004081887946637586\n"
     ]
    }
   ],
   "source": [
    "model_training(predictors,target,regression_model=regression_model(),epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc7977e1-84ce-480a-9d3b-0ff6178b2c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 - 13s - 549ms/step - loss: 1588.0471 - val_loss: 1053.3977\n",
      "Epoch 2/100\n",
      "23/23 - 0s - 20ms/step - loss: 1269.5583 - val_loss: 777.5127\n",
      "Epoch 3/100\n",
      "23/23 - 1s - 30ms/step - loss: 806.3644 - val_loss: 433.1950\n",
      "Epoch 4/100\n",
      "23/23 - 0s - 19ms/step - loss: 386.2609 - val_loss: 214.1478\n",
      "Epoch 5/100\n",
      "23/23 - 0s - 19ms/step - loss: 251.1802 - val_loss: 175.8321\n",
      "Epoch 6/100\n",
      "23/23 - 0s - 20ms/step - loss: 226.3924 - val_loss: 169.0334\n",
      "Epoch 7/100\n",
      "23/23 - 0s - 20ms/step - loss: 207.0029 - val_loss: 163.3777\n",
      "Epoch 8/100\n",
      "23/23 - 1s - 28ms/step - loss: 195.1004 - val_loss: 158.9497\n",
      "Epoch 9/100\n",
      "23/23 - 0s - 22ms/step - loss: 185.4662 - val_loss: 156.2041\n",
      "Epoch 10/100\n",
      "23/23 - 1s - 24ms/step - loss: 177.6386 - val_loss: 153.8455\n",
      "Epoch 11/100\n",
      "23/23 - 1s - 25ms/step - loss: 170.8777 - val_loss: 154.2149\n",
      "Epoch 12/100\n",
      "23/23 - 1s - 25ms/step - loss: 166.5253 - val_loss: 153.8207\n",
      "Epoch 13/100\n",
      "23/23 - 0s - 19ms/step - loss: 161.3666 - val_loss: 149.3184\n",
      "Epoch 14/100\n",
      "23/23 - 0s - 21ms/step - loss: 157.6143 - val_loss: 150.5774\n",
      "Epoch 15/100\n",
      "23/23 - 1s - 23ms/step - loss: 154.4065 - val_loss: 151.0838\n",
      "Epoch 16/100\n",
      "23/23 - 0s - 20ms/step - loss: 151.0343 - val_loss: 151.6996\n",
      "Epoch 17/100\n",
      "23/23 - 1s - 29ms/step - loss: 148.5556 - val_loss: 152.2607\n",
      "Epoch 18/100\n",
      "23/23 - 0s - 19ms/step - loss: 146.4816 - val_loss: 152.1262\n",
      "Epoch 19/100\n",
      "23/23 - 1s - 32ms/step - loss: 144.1947 - val_loss: 153.2545\n",
      "Epoch 20/100\n",
      "23/23 - 1s - 27ms/step - loss: 142.5239 - val_loss: 152.4635\n",
      "Epoch 21/100\n",
      "23/23 - 0s - 15ms/step - loss: 139.5920 - val_loss: 155.2995\n",
      "Epoch 22/100\n",
      "23/23 - 0s - 16ms/step - loss: 137.6497 - val_loss: 157.0005\n",
      "Epoch 23/100\n",
      "23/23 - 0s - 17ms/step - loss: 135.6048 - val_loss: 157.2662\n",
      "Epoch 24/100\n",
      "23/23 - 1s - 32ms/step - loss: 132.9922 - val_loss: 155.8234\n",
      "Epoch 25/100\n",
      "23/23 - 0s - 18ms/step - loss: 130.2467 - val_loss: 158.3529\n",
      "Epoch 26/100\n",
      "23/23 - 0s - 16ms/step - loss: 125.9008 - val_loss: 156.3842\n",
      "Epoch 27/100\n",
      "23/23 - 0s - 20ms/step - loss: 122.6664 - val_loss: 159.8445\n",
      "Epoch 28/100\n",
      "23/23 - 0s - 14ms/step - loss: 118.3057 - val_loss: 159.1530\n",
      "Epoch 29/100\n",
      "23/23 - 0s - 14ms/step - loss: 113.6442 - val_loss: 157.3730\n",
      "Epoch 30/100\n",
      "23/23 - 0s - 20ms/step - loss: 108.7403 - val_loss: 162.2316\n",
      "Epoch 31/100\n",
      "23/23 - 0s - 19ms/step - loss: 104.2811 - val_loss: 156.9103\n",
      "Epoch 32/100\n",
      "23/23 - 1s - 22ms/step - loss: 99.4106 - val_loss: 158.8198\n",
      "Epoch 33/100\n",
      "23/23 - 0s - 17ms/step - loss: 95.4230 - val_loss: 155.0485\n",
      "Epoch 34/100\n",
      "23/23 - 1s - 33ms/step - loss: 90.3151 - val_loss: 157.3536\n",
      "Epoch 35/100\n",
      "23/23 - 0s - 21ms/step - loss: 86.6295 - val_loss: 158.3952\n",
      "Epoch 36/100\n",
      "23/23 - 0s - 21ms/step - loss: 82.6718 - val_loss: 154.1160\n",
      "Epoch 37/100\n",
      "23/23 - 0s - 19ms/step - loss: 78.9950 - val_loss: 153.0521\n",
      "Epoch 38/100\n",
      "23/23 - 0s - 18ms/step - loss: 75.4941 - val_loss: 155.0488\n",
      "Epoch 39/100\n",
      "23/23 - 1s - 31ms/step - loss: 72.2210 - val_loss: 152.8206\n",
      "Epoch 40/100\n",
      "23/23 - 0s - 22ms/step - loss: 68.9607 - val_loss: 149.5495\n",
      "Epoch 41/100\n",
      "23/23 - 0s - 20ms/step - loss: 66.0878 - val_loss: 150.2273\n",
      "Epoch 42/100\n",
      "23/23 - 0s - 18ms/step - loss: 64.9634 - val_loss: 145.7459\n",
      "Epoch 43/100\n",
      "23/23 - 0s - 20ms/step - loss: 61.8096 - val_loss: 147.5201\n",
      "Epoch 44/100\n",
      "23/23 - 1s - 30ms/step - loss: 60.3254 - val_loss: 138.3816\n",
      "Epoch 45/100\n",
      "23/23 - 1s - 28ms/step - loss: 57.8363 - val_loss: 146.2862\n",
      "Epoch 46/100\n",
      "23/23 - 0s - 17ms/step - loss: 55.7527 - val_loss: 147.9446\n",
      "Epoch 47/100\n",
      "23/23 - 1s - 31ms/step - loss: 54.4000 - val_loss: 143.4408\n",
      "Epoch 48/100\n",
      "23/23 - 0s - 18ms/step - loss: 52.3733 - val_loss: 142.7655\n",
      "Epoch 49/100\n",
      "23/23 - 1s - 22ms/step - loss: 51.0264 - val_loss: 144.0979\n",
      "Epoch 50/100\n",
      "23/23 - 0s - 19ms/step - loss: 49.2836 - val_loss: 145.7675\n",
      "Epoch 51/100\n",
      "23/23 - 1s - 24ms/step - loss: 48.5367 - val_loss: 145.8271\n",
      "Epoch 52/100\n",
      "23/23 - 0s - 16ms/step - loss: 47.0197 - val_loss: 138.6242\n",
      "Epoch 53/100\n",
      "23/23 - 1s - 28ms/step - loss: 45.5159 - val_loss: 142.5056\n",
      "Epoch 54/100\n",
      "23/23 - 1s - 28ms/step - loss: 45.2570 - val_loss: 137.6413\n",
      "Epoch 55/100\n",
      "23/23 - 1s - 33ms/step - loss: 44.1658 - val_loss: 145.9261\n",
      "Epoch 56/100\n",
      "23/23 - 0s - 15ms/step - loss: 42.9460 - val_loss: 147.8000\n",
      "Epoch 57/100\n",
      "23/23 - 0s - 17ms/step - loss: 41.9509 - val_loss: 141.2108\n",
      "Epoch 58/100\n",
      "23/23 - 0s - 16ms/step - loss: 40.8584 - val_loss: 138.6687\n",
      "Epoch 59/100\n",
      "23/23 - 0s - 16ms/step - loss: 40.5507 - val_loss: 145.9663\n",
      "Epoch 60/100\n",
      "23/23 - 0s - 17ms/step - loss: 39.2102 - val_loss: 141.2085\n",
      "Epoch 61/100\n",
      "23/23 - 0s - 17ms/step - loss: 39.5991 - val_loss: 148.8843\n",
      "Epoch 62/100\n",
      "23/23 - 1s - 23ms/step - loss: 38.4196 - val_loss: 148.7380\n",
      "Epoch 63/100\n",
      "23/23 - 1s - 24ms/step - loss: 37.2508 - val_loss: 163.1613\n",
      "Epoch 64/100\n",
      "23/23 - 1s - 29ms/step - loss: 37.1594 - val_loss: 150.5133\n",
      "Epoch 65/100\n",
      "23/23 - 1s - 27ms/step - loss: 36.9530 - val_loss: 163.2740\n",
      "Epoch 66/100\n",
      "23/23 - 0s - 19ms/step - loss: 35.8609 - val_loss: 157.8680\n",
      "Epoch 67/100\n",
      "23/23 - 0s - 19ms/step - loss: 34.8825 - val_loss: 157.4136\n",
      "Epoch 68/100\n",
      "23/23 - 1s - 27ms/step - loss: 34.8653 - val_loss: 148.7503\n",
      "Epoch 69/100\n",
      "23/23 - 0s - 20ms/step - loss: 34.4310 - val_loss: 157.9647\n",
      "Epoch 70/100\n",
      "23/23 - 0s - 17ms/step - loss: 33.6477 - val_loss: 164.2956\n",
      "Epoch 71/100\n",
      "23/23 - 0s - 19ms/step - loss: 33.4754 - val_loss: 147.2664\n",
      "Epoch 72/100\n",
      "23/23 - 0s - 17ms/step - loss: 32.7929 - val_loss: 150.8689\n",
      "Epoch 73/100\n",
      "23/23 - 0s - 20ms/step - loss: 32.1612 - val_loss: 164.4365\n",
      "Epoch 74/100\n",
      "23/23 - 0s - 17ms/step - loss: 31.9119 - val_loss: 153.0418\n",
      "Epoch 75/100\n",
      "23/23 - 1s - 31ms/step - loss: 31.1361 - val_loss: 157.1721\n",
      "Epoch 76/100\n",
      "23/23 - 1s - 30ms/step - loss: 31.0524 - val_loss: 152.7063\n",
      "Epoch 77/100\n",
      "23/23 - 0s - 20ms/step - loss: 30.5879 - val_loss: 156.8405\n",
      "Epoch 78/100\n",
      "23/23 - 1s - 27ms/step - loss: 30.0629 - val_loss: 164.5954\n",
      "Epoch 79/100\n",
      "23/23 - 0s - 21ms/step - loss: 30.0442 - val_loss: 137.7536\n",
      "Epoch 80/100\n",
      "23/23 - 1s - 29ms/step - loss: 29.8444 - val_loss: 143.5695\n",
      "Epoch 81/100\n",
      "23/23 - 0s - 17ms/step - loss: 29.5579 - val_loss: 156.4630\n",
      "Epoch 82/100\n",
      "23/23 - 0s - 19ms/step - loss: 29.5270 - val_loss: 145.1785\n",
      "Epoch 83/100\n",
      "23/23 - 0s - 18ms/step - loss: 28.5341 - val_loss: 160.8111\n",
      "Epoch 84/100\n",
      "23/23 - 1s - 29ms/step - loss: 28.1190 - val_loss: 153.4994\n",
      "Epoch 85/100\n",
      "23/23 - 0s - 19ms/step - loss: 28.4611 - val_loss: 160.1280\n",
      "Epoch 86/100\n",
      "23/23 - 1s - 29ms/step - loss: 28.2770 - val_loss: 164.8642\n",
      "Epoch 87/100\n",
      "23/23 - 1s - 26ms/step - loss: 27.5434 - val_loss: 160.1134\n",
      "Epoch 88/100\n",
      "23/23 - 0s - 17ms/step - loss: 26.8914 - val_loss: 151.0395\n",
      "Epoch 89/100\n",
      "23/23 - 0s - 16ms/step - loss: 26.7326 - val_loss: 152.3137\n",
      "Epoch 90/100\n",
      "23/23 - 0s - 19ms/step - loss: 26.3347 - val_loss: 150.5338\n",
      "Epoch 91/100\n",
      "23/23 - 0s - 14ms/step - loss: 25.9781 - val_loss: 156.4754\n",
      "Epoch 92/100\n",
      "23/23 - 1s - 31ms/step - loss: 26.0428 - val_loss: 157.9348\n",
      "Epoch 93/100\n",
      "23/23 - 1s - 33ms/step - loss: 25.8593 - val_loss: 155.1719\n",
      "Epoch 94/100\n",
      "23/23 - 1s - 31ms/step - loss: 26.4960 - val_loss: 166.2694\n",
      "Epoch 95/100\n",
      "23/23 - 1s - 26ms/step - loss: 25.4754 - val_loss: 159.0557\n",
      "Epoch 96/100\n",
      "23/23 - 0s - 19ms/step - loss: 24.7729 - val_loss: 164.7899\n",
      "Epoch 97/100\n",
      "23/23 - 0s - 21ms/step - loss: 24.9148 - val_loss: 152.9874\n",
      "Epoch 98/100\n",
      "23/23 - 0s - 19ms/step - loss: 24.1290 - val_loss: 144.7178\n",
      "Epoch 99/100\n",
      "23/23 - 0s - 19ms/step - loss: 24.2608 - val_loss: 133.9958\n",
      "Epoch 100/100\n",
      "23/23 - 1s - 33ms/step - loss: 24.1790 - val_loss: 148.8701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2132d7ba3c0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors,targetY, validation_split=0.3,epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fa7e0e99-cf0f-409c-9936-90fbaa668751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 - 0s - 12ms/step - loss: 60.9356\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(predictors, targetY, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d45b2e9a-7d3b-423d-9c49-987460672f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.94% \n",
      "Error: -59.94\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2f}% \\nError: {:.2f}'.format(scores, (1 - scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "59c80a65-456f-4e68-acab-6336c3c493e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('regression_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e73feb-8fbb-4ecc-85d9-a01187b2a423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38beca34-c1fc-4c98-9233-14372f7520ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547dcff-96e8-443d-a987-831d1ef37231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
